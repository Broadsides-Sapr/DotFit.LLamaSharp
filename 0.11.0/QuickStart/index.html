
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="..">
      
      
        <link rel="next" href="../Architecture/">
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.4.3, mkdocs-material-9.1.20">
    
    
      
        <title>Quick Start - LLamaSharp Documentation</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.eebd395e.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#quick-start" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-color-scheme="default" data-md-component="outdated" hidden>
        
      </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="LLamaSharp Documentation" class="md-header__button md-logo" aria-label="LLamaSharp Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            LLamaSharp Documentation
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Quick Start
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="LLamaSharp Documentation" class="md-nav__button md-logo" aria-label="LLamaSharp Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    LLamaSharp Documentation
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        Overview
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Quick Start
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Quick Start
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#installation" class="md-nav__link">
    Installation
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model-preparation" class="md-nav__link">
    Model preparation
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#example-of-llama-chat-session" class="md-nav__link">
    Example of LLaMA chat session
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples-of-chatting-with-llava" class="md-nav__link">
    Examples of chatting with LLaVA
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../Architecture/" class="md-nav__link">
        Architecture
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../FAQ/" class="md-nav__link">
        FAQ
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../ContributingGuide/" class="md-nav__link">
        Contributing Guide
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
      
      
      
        <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
          Tutorials
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_6">
          <span class="md-nav__icon md-icon"></span>
          Tutorials
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Tutorials/NativeLibraryConfig/" class="md-nav__link">
        Customize the native library loading
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Tutorials/Executors/" class="md-nav__link">
        Use executors
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Tutorials/ChatSession/" class="md-nav__link">
        Use ChatSession
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Tutorials/UnderstandLLamaContext/" class="md-nav__link">
        Understand LLamaContext
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Tutorials/GetEmbeddings/" class="md-nav__link">
        Get embeddings
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Tutorials/Quantization/" class="md-nav__link">
        Quantize the model
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
      
      
      
        <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
          Integrations
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_7">
          <span class="md-nav__icon md-icon"></span>
          Integrations
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Integrations/semantic-kernel/" class="md-nav__link">
        semantic-kernel integration
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Integrations/kernel-memory/" class="md-nav__link">
        kernel-memory integration
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Integrations/BotSharp.md" class="md-nav__link">
        BotSharp integration
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Integrations/Langchain.md" class="md-nav__link">
        Langchain integration
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_8" >
      
      
      
        <label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="0">
          Examples
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_8">
          <span class="md-nav__icon md-icon"></span>
          Examples
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Examples/BatchedExecutorFork/" class="md-nav__link">
        Bacthed executor - multi-output to one input
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Examples/BatchedExecutorGuidance/" class="md-nav__link">
        Batched executor - basic guidance
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Examples/BatchedExecutorRewind/" class="md-nav__link">
        Batched executor - rewinding to an earlier state
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Examples/ChatChineseGB2312/" class="md-nav__link">
        Chinese LLM - with GB2312 encoding
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Examples/ChatSessionStripRoleName/" class="md-nav__link">
        ChatSession - stripping role names
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Examples/ChatSessionWithHistory/" class="md-nav__link">
        ChatSession - with history
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Examples/ChatSessionWithRestart/" class="md-nav__link">
        ChatSession - restarting
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Examples/ChatSessionWithRoleName/" class="md-nav__link">
        ChatSession - Basic
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Examples/CodingAssistant/" class="md-nav__link">
        Coding assistant
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Examples/GetEmbeddings/" class="md-nav__link">
        Get embeddings
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Examples/GrammarJsonResponse/" class="md-nav__link">
        Grammar - json response
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Examples/InstructModeExecute/" class="md-nav__link">
        Instruct executor - basic
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Examples/InteractiveModeExecute/" class="md-nav__link">
        Interactive executor - basic
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Examples/KernelMemory/" class="md-nav__link">
        Kernel memory integration - basic
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Examples/KernelMemorySaveAndLoad/" class="md-nav__link">
        Kernel-memory - save & load
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Examples/LLavaInteractiveModeExecute/" class="md-nav__link">
        LLaVA - basic
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Examples/LoadAndSaveSession/" class="md-nav__link">
        ChatSession - load & save
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Examples/LoadAndSaveState/" class="md-nav__link">
        Executor - save/load state
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Examples/QuantizeModel/" class="md-nav__link">
        Quantization
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Examples/SemanticKernelChat/" class="md-nav__link">
        Semantic-kernel - chat
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Examples/SemanticKernelMemory/" class="md-nav__link">
        Semantic-kernel - with kernel-memory
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Examples/SemanticKernelPrompt/" class="md-nav__link">
        Semantic-kernel - basic
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Examples/StatelessModeExecute/" class="md-nav__link">
        Stateless executor
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Examples/TalkToYourself/" class="md-nav__link">
        Talk to yourself
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_9" >
      
      
      
        <label class="md-nav__link" for="__nav_9" id="__nav_9_label" tabindex="0">
          API Reference
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_9_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_9">
          <span class="md-nav__icon md-icon"></span>
          API Reference
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/" class="md-nav__link">
        index
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.abstractions.adaptercollection/" class="md-nav__link">
        llama.abstractions.adaptercollection
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.abstractions.icontextparams/" class="md-nav__link">
        llama.abstractions.icontextparams
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.abstractions.ihistorytransform/" class="md-nav__link">
        llama.abstractions.ihistorytransform
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.abstractions.iinferenceparams/" class="md-nav__link">
        llama.abstractions.iinferenceparams
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.abstractions.illamaexecutor/" class="md-nav__link">
        llama.abstractions.illamaexecutor
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.abstractions.illamaparams/" class="md-nav__link">
        llama.abstractions.illamaparams
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.abstractions.imodelparams/" class="md-nav__link">
        llama.abstractions.imodelparams
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.abstractions.itextstreamtransform/" class="md-nav__link">
        llama.abstractions.itextstreamtransform
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.abstractions.itexttransform/" class="md-nav__link">
        llama.abstractions.itexttransform
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.abstractions.loraadapter/" class="md-nav__link">
        llama.abstractions.loraadapter
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.abstractions.metadataoverride/" class="md-nav__link">
        llama.abstractions.metadataoverride
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.abstractions.metadataoverrideconverter/" class="md-nav__link">
        llama.abstractions.metadataoverrideconverter
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.abstractions.tensorsplitscollection/" class="md-nav__link">
        llama.abstractions.tensorsplitscollection
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.abstractions.tensorsplitscollectionconverter/" class="md-nav__link">
        llama.abstractions.tensorsplitscollectionconverter
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.antipromptprocessor/" class="md-nav__link">
        llama.antipromptprocessor
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.batched.alreadypromptedconversationexception/" class="md-nav__link">
        llama.batched.alreadypromptedconversationexception
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.batched.batchedexecutor/" class="md-nav__link">
        llama.batched.batchedexecutor
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.batched.cannotforkwhilerequiresinferenceexception/" class="md-nav__link">
        llama.batched.cannotforkwhilerequiresinferenceexception
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.batched.cannotmodifywhilerequiresinferenceexception/" class="md-nav__link">
        llama.batched.cannotmodifywhilerequiresinferenceexception
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.batched.cannotsamplerequiresinferenceexception/" class="md-nav__link">
        llama.batched.cannotsamplerequiresinferenceexception
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.batched.cannotsamplerequirespromptexception/" class="md-nav__link">
        llama.batched.cannotsamplerequirespromptexception
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.batched.conversation/" class="md-nav__link">
        llama.batched.conversation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.batched.conversationextensions/" class="md-nav__link">
        llama.batched.conversationextensions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.batched.experimentalbatchedexecutorexception/" class="md-nav__link">
        llama.batched.experimentalbatchedexecutorexception
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.chatsession-1/" class="md-nav__link">
        llama.chatsession-1
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.chatsession/" class="md-nav__link">
        llama.chatsession
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.common.authorrole/" class="md-nav__link">
        llama.common.authorrole
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.common.chathistory/" class="md-nav__link">
        llama.common.chathistory
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.common.fixedsizequeue-1/" class="md-nav__link">
        llama.common.fixedsizequeue-1
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.common.inferenceparams/" class="md-nav__link">
        llama.common.inferenceparams
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.common.mirostattype/" class="md-nav__link">
        llama.common.mirostattype
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.common.modelparams/" class="md-nav__link">
        llama.common.modelparams
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.exceptions.grammarexpectedname/" class="md-nav__link">
        llama.exceptions.grammarexpectedname
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.exceptions.grammarexpectednext/" class="md-nav__link">
        llama.exceptions.grammarexpectednext
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.exceptions.grammarexpectedprevious/" class="md-nav__link">
        llama.exceptions.grammarexpectedprevious
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.exceptions.grammarformatexception/" class="md-nav__link">
        llama.exceptions.grammarformatexception
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.exceptions.grammarunexpectedcharaltelement/" class="md-nav__link">
        llama.exceptions.grammarunexpectedcharaltelement
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.exceptions.grammarunexpectedcharrngelement/" class="md-nav__link">
        llama.exceptions.grammarunexpectedcharrngelement
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.exceptions.grammarunexpectedendelement/" class="md-nav__link">
        llama.exceptions.grammarunexpectedendelement
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.exceptions.grammarunexpectedendofinput/" class="md-nav__link">
        llama.exceptions.grammarunexpectedendofinput
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.exceptions.grammarunexpectedhexcharscount/" class="md-nav__link">
        llama.exceptions.grammarunexpectedhexcharscount
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.exceptions.grammarunknownescapecharacter/" class="md-nav__link">
        llama.exceptions.grammarunknownescapecharacter
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.exceptions.llamadecodeerror/" class="md-nav__link">
        llama.exceptions.llamadecodeerror
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.exceptions.loadweightsfailedexception/" class="md-nav__link">
        llama.exceptions.loadweightsfailedexception
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.exceptions.runtimeerror/" class="md-nav__link">
        llama.exceptions.runtimeerror
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.extensions.icontextparamsextensions/" class="md-nav__link">
        llama.extensions.icontextparamsextensions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.extensions.imodelparamsextensions/" class="md-nav__link">
        llama.extensions.imodelparamsextensions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.grammars.grammar/" class="md-nav__link">
        llama.grammars.grammar
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.grammars.grammarrule/" class="md-nav__link">
        llama.grammars.grammarrule
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.ichatmodel/" class="md-nav__link">
        llama.ichatmodel
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.llamacache/" class="md-nav__link">
        llama.llamacache
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.llamaembedder/" class="md-nav__link">
        llama.llamaembedder
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.llamamodel/" class="md-nav__link">
        llama.llamamodel
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.llamamodelv1/" class="md-nav__link">
        llama.llamamodelv1
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.llamaparams/" class="md-nav__link">
        llama.llamaparams
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.llamaquantizer/" class="md-nav__link">
        llama.llamaquantizer
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.llamastate/" class="md-nav__link">
        llama.llamastate
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.llamatransforms/" class="md-nav__link">
        llama.llamatransforms
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.llavaweights/" class="md-nav__link">
        llama.llavaweights
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.native.decoderesult/" class="md-nav__link">
        llama.native.decoderesult
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.native.ggmltype/" class="md-nav__link">
        llama.native.ggmltype
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.native.gpusplitmode/" class="md-nav__link">
        llama.native.gpusplitmode
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.native.llamabatch/" class="md-nav__link">
        llama.native.llamabatch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.native.llamabeamsstate/" class="md-nav__link">
        llama.native.llamabeamsstate
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.native.llamabeamview/" class="md-nav__link">
        llama.native.llamabeamview
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.native.llamachatmessage/" class="md-nav__link">
        llama.native.llamachatmessage
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.native.llamacontextparams/" class="md-nav__link">
        llama.native.llamacontextparams
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.native.llamaftype/" class="md-nav__link">
        llama.native.llamaftype
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.native.llamagrammarelement/" class="md-nav__link">
        llama.native.llamagrammarelement
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.native.llamagrammarelementtype/" class="md-nav__link">
        llama.native.llamagrammarelementtype
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.native.llamakvcacheview/" class="md-nav__link">
        llama.native.llamakvcacheview
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.native.llamakvcacheviewcell/" class="md-nav__link">
        llama.native.llamakvcacheviewcell
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.native.llamakvcacheviewsafehandle/" class="md-nav__link">
        llama.native.llamakvcacheviewsafehandle
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.native.llamaloglevel/" class="md-nav__link">
        llama.native.llamaloglevel
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.native.llamamodelkvoverridetype/" class="md-nav__link">
        llama.native.llamamodelkvoverridetype
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.native.llamamodelmetadataoverride/" class="md-nav__link">
        llama.native.llamamodelmetadataoverride
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.native.llamamodelparams/" class="md-nav__link">
        llama.native.llamamodelparams
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.native.llamamodelquantizeparams/" class="md-nav__link">
        llama.native.llamamodelquantizeparams
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.native.llamanativebatch/" class="md-nav__link">
        llama.native.llamanativebatch
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.native.llamapoolingtype/" class="md-nav__link">
        llama.native.llamapoolingtype
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.native.llamapos/" class="md-nav__link">
        llama.native.llamapos
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.native.llamaropetype/" class="md-nav__link">
        llama.native.llamaropetype
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.native.llamaseqid/" class="md-nav__link">
        llama.native.llamaseqid
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.native.llamatoken/" class="md-nav__link">
        llama.native.llamatoken
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.native.llamatokendata/" class="md-nav__link">
        llama.native.llamatokendata
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.native.llamatokendataarray/" class="md-nav__link">
        llama.native.llamatokendataarray
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.native.llamatokendataarraynative/" class="md-nav__link">
        llama.native.llamatokendataarraynative
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.native.llamatokentype/" class="md-nav__link">
        llama.native.llamatokentype
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.native.llamavocabtype/" class="md-nav__link">
        llama.native.llamavocabtype
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.native.llavaimageembed/" class="md-nav__link">
        llama.native.llavaimageembed
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.native.nativeapi/" class="md-nav__link">
        llama.native.nativeapi
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.native.nativelibraryconfig/" class="md-nav__link">
        llama.native.nativelibraryconfig
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.native.ropescalingtype/" class="md-nav__link">
        llama.native.ropescalingtype
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.native.safellamacontexthandle/" class="md-nav__link">
        llama.native.safellamacontexthandle
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.native.safellamagrammarhandle/" class="md-nav__link">
        llama.native.safellamagrammarhandle
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.native.safellamahandlebase/" class="md-nav__link">
        llama.native.safellamahandlebase
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.native.safellamamodelhandle/" class="md-nav__link">
        llama.native.safellamamodelhandle
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.native.safellavaimageembedhandle/" class="md-nav__link">
        llama.native.safellavaimageembedhandle
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.native.safellavamodelhandle/" class="md-nav__link">
        llama.native.safellavamodelhandle
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.quantizer/" class="md-nav__link">
        llama.quantizer
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.sampling.basesamplingpipeline/" class="md-nav__link">
        llama.sampling.basesamplingpipeline
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.sampling.defaultsamplingpipeline/" class="md-nav__link">
        llama.sampling.defaultsamplingpipeline
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.sampling.greedysamplingpipeline/" class="md-nav__link">
        llama.sampling.greedysamplingpipeline
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.sampling.isamplingpipeline/" class="md-nav__link">
        llama.sampling.isamplingpipeline
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.sampling.isamplingpipelineextensions/" class="md-nav__link">
        llama.sampling.isamplingpipelineextensions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.sampling.mirostate2samplingpipeline/" class="md-nav__link">
        llama.sampling.mirostate2samplingpipeline
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.sampling.mirostatesamplingpipeline/" class="md-nav__link">
        llama.sampling.mirostatesamplingpipeline
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.sessionstate/" class="md-nav__link">
        llama.sessionstate
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.streamingtokendecoder/" class="md-nav__link">
        llama.streamingtokendecoder
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.types.chatcompletion/" class="md-nav__link">
        llama.types.chatcompletion
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.types.chatcompletionchoice/" class="md-nav__link">
        llama.types.chatcompletionchoice
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.types.chatcompletionchunk/" class="md-nav__link">
        llama.types.chatcompletionchunk
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.types.chatcompletionchunkchoice/" class="md-nav__link">
        llama.types.chatcompletionchunkchoice
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.types.chatcompletionchunkdelta/" class="md-nav__link">
        llama.types.chatcompletionchunkdelta
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.types.chatcompletionmessage/" class="md-nav__link">
        llama.types.chatcompletionmessage
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.types.chatmessagerecord/" class="md-nav__link">
        llama.types.chatmessagerecord
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.types.chatrole/" class="md-nav__link">
        llama.types.chatrole
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.types.completion/" class="md-nav__link">
        llama.types.completion
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.types.completionchoice/" class="md-nav__link">
        llama.types.completionchoice
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.types.completionchunk/" class="md-nav__link">
        llama.types.completionchunk
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.types.completionlogprobs/" class="md-nav__link">
        llama.types.completionlogprobs
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.types.completionusage/" class="md-nav__link">
        llama.types.completionusage
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.types.embedding/" class="md-nav__link">
        llama.types.embedding
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.types.embeddingdata/" class="md-nav__link">
        llama.types.embeddingdata
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/llama.types.embeddingusage/" class="md-nav__link">
        llama.types.embeddingusage
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../xmldocs/logger/" class="md-nav__link">
        logger
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#installation" class="md-nav__link">
    Installation
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model-preparation" class="md-nav__link">
    Model preparation
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#example-of-llama-chat-session" class="md-nav__link">
    Example of LLaMA chat session
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples-of-chatting-with-llava" class="md-nav__link">
    Examples of chatting with LLaVA
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="quick-start">Quick start</h1>
<h2 id="installation">Installation</h2>
<p>To gain high performance, LLamaSharp interacts with a native library compiled from c++, which is called <code>backend</code>. We provide backend packages for Windows, Linux and MAC with CPU, Cuda, Metal and OpenCL. You <strong>don't</strong> need to handle anything about c++ but just install the backend packages.</p>
<p>If no published backend match your device, please open an issue to let us know. If compiling c++ code is not difficult for you, you could also follow <a href="../ContributingGuide/">this guide</a> to compile a backend and run LLamaSharp with it.</p>
<ol>
<li>Install <a href="https://www.nuget.org/packages/LLamaSharp">LLamaSharp</a> package on NuGet:</li>
</ol>
<pre><code>PM&gt; Install-Package LLamaSharp
</code></pre>
<ol>
<li>
<p>Install one or more of these backends, or use self-compiled backend.</p>
</li>
<li>
<p><a href="https://www.nuget.org/packages/LLamaSharp.Backend.Cpu"><code>LLamaSharp.Backend.Cpu</code></a>: Pure CPU for Windows &amp; Linux &amp; MAC. Metal (GPU) support for MAC.</p>
</li>
<li><a href="https://www.nuget.org/packages/LLamaSharp.Backend.Cuda11"><code>LLamaSharp.Backend.Cuda11</code></a>: CUDA11 for Windows &amp; Linux.</li>
<li><a href="https://www.nuget.org/packages/LLamaSharp.Backend.Cuda12"><code>LLamaSharp.Backend.Cuda12</code></a>: CUDA 12 for Windows &amp; Linux.</li>
<li>
<p><a href="https://www.nuget.org/packages/LLamaSharp.Backend.OpenCL"><code>LLamaSharp.Backend.OpenCL</code></a>: OpenCL for Windows &amp; Linux.</p>
</li>
<li>
<p>(optional) For <a href="https://github.com/microsoft/semantic-kernel">Microsoft semantic-kernel</a> integration, install the <a href="https://www.nuget.org/packages/LLamaSharp.semantic-kernel">LLamaSharp.semantic-kernel</a> package.</p>
</li>
<li>(optional) To enable RAG support, install the <a href="https://www.nuget.org/packages/LLamaSharp.kernel-memory">LLamaSharp.kernel-memory</a> package (this package only supports <code>net6.0</code> or higher yet), which is based on <a href="https://github.com/microsoft/kernel-memory">Microsoft kernel-memory</a> integration.</li>
</ol>
<h2 id="model-preparation">Model preparation</h2>
<p>There are two popular format of model file of LLM now, which are PyTorch format (.pth) and Huggingface format (.bin). LLamaSharp uses <code>GGUF</code> format file, which could be converted from these two formats. To get <code>GGUF</code> file, there are two options:</p>
<ol>
<li>
<p>Search model name + 'gguf' in <a href="https://huggingface.co">Huggingface</a>, you will find lots of model files that have already been converted to GGUF format. Please take care of the publishing time of them because some old ones could only work with old version of LLamaSharp.</p>
</li>
<li>
<p>Convert PyTorch or Huggingface format to GGUF format yourself. Please follow the instructions of <a href="https://github.com/ggerganov/llama.cpp?tab=readme-ov-file#prepare-and-quantize">this part of llama.cpp readme</a> to convert them with the python scripts.</p>
</li>
</ol>
<p>Generally, we recommend downloading models with quantization rather than fp16, because it significantly reduce the required memory size while only slightly impact on its generation quality.</p>
<h2 id="example-of-llama-chat-session">Example of LLaMA chat session</h2>
<p>Here is a simple example to chat with bot based on LLM in LLamaSharp. Please replace the model path with yours.</p>
<p><img alt="llama_demo" src="../media/console_demo.gif" /></p>
<pre><code class="language-cs">using LLama.Common;
using LLama;

string modelPath = @&quot;&lt;Your Model Path&gt;&quot;; // change it to your own model path.

var parameters = new ModelParams(modelPath)
{
    ContextSize = 1024, // The longest length of chat as memory.
    GpuLayerCount = 5 // How many layers to offload to GPU. Please adjust it according to your GPU memory.
};
using var model = LLamaWeights.LoadFromFile(parameters);
using var context = model.CreateContext(parameters);
var executor = new InteractiveExecutor(context);

// Add chat histories as prompt to tell AI how to act.
var chatHistory = new ChatHistory();
chatHistory.AddMessage(AuthorRole.System, &quot;Transcript of a dialog, where the User interacts with an Assistant named Bob. Bob is helpful, kind, honest, good at writing, and never fails to answer the User's requests immediately and with precision.&quot;);
chatHistory.AddMessage(AuthorRole.User, &quot;Hello, Bob.&quot;);
chatHistory.AddMessage(AuthorRole.Assistant, &quot;Hello. How may I help you today?&quot;);

ChatSession session = new(executor, chatHistory);

InferenceParams inferenceParams = new InferenceParams()
{
    MaxTokens = 256, // No more than 256 tokens should appear in answer. Remove it if antiprompt is enough for control.
    AntiPrompts = new List&lt;string&gt; { &quot;User:&quot; } // Stop generation once antiprompts appear.
};

Console.ForegroundColor = ConsoleColor.Yellow;
Console.Write(&quot;The chat session has started.\nUser: &quot;);
Console.ForegroundColor = ConsoleColor.Green;
string userInput = Console.ReadLine() ?? &quot;&quot;;

while (userInput != &quot;exit&quot;)
{
    await foreach ( // Generate the response streamingly.
        var text
        in session.ChatAsync(
            new ChatHistory.Message(AuthorRole.User, userInput),
            inferenceParams))
    {
        Console.ForegroundColor = ConsoleColor.White;
        Console.Write(text);
    }
    Console.ForegroundColor = ConsoleColor.Green;
    userInput = Console.ReadLine() ?? &quot;&quot;;
}
</code></pre>
<h2 id="examples-of-chatting-with-llava">Examples of chatting with LLaVA</h2>
<p>This example shows chatting with LLaVA to ask it to describe the picture.
<img alt="llava_demo" src="../media/llava_demo.gif" /></p>
<pre><code class="language-cs">using System.Text.RegularExpressions;
using LLama;
using LLama.Common;

string multiModalProj = @&quot;&lt;Your multi-modal proj file path&gt;&quot;;
string modelPath = @&quot;&lt;Your LLaVA model file path&gt;&quot;;
string modelImage = @&quot;&lt;Your image path&gt;&quot;;
const int maxTokens = 1024; // The max tokens that could be generated.

var prompt = $&quot;{{{modelImage}}}\nUSER:\nProvide a full description of the image.\nASSISTANT:\n&quot;;

var parameters = new ModelParams(modelPath)
{
    ContextSize = 4096,
    Seed = 1337,
};
using var model = LLamaWeights.LoadFromFile(parameters);
using var context = model.CreateContext(parameters);

// Llava Init
using var clipModel = LLavaWeights.LoadFromFile(multiModalProj);

var ex = new InteractiveExecutor(context, clipModel);

Console.ForegroundColor = ConsoleColor.Yellow;
Console.WriteLine(&quot;The executor has been enabled. In this example, the prompt is printed, the maximum tokens is set to {0} and the context size is {1}.&quot;, maxTokens, parameters.ContextSize);
Console.WriteLine(&quot;To send an image, enter its filename in curly braces, like this {c:/image.jpg}.&quot;);

var inferenceParams = new InferenceParams() { Temperature = 0.1f, AntiPrompts = new List&lt;string&gt; { &quot;\nUSER:&quot; }, MaxTokens = maxTokens };

do
{

    // Evaluate if we have images
    //
    var imageMatches = Regex.Matches(prompt, &quot;{([^}]*)}&quot;).Select(m =&gt; m.Value);
    var imageCount = imageMatches.Count();
    var hasImages = imageCount &gt; 0;
    byte[][] imageBytes = null;

    if (hasImages)
    {
        var imagePathsWithCurlyBraces = Regex.Matches(prompt, &quot;{([^}]*)}&quot;).Select(m =&gt; m.Value);
        var imagePaths = Regex.Matches(prompt, &quot;{([^}]*)}&quot;).Select(m =&gt; m.Groups[1].Value);

        try
        {
            imageBytes = imagePaths.Select(File.ReadAllBytes).ToArray();
        }
        catch (IOException exception)
        {
            Console.ForegroundColor = ConsoleColor.Red;
            Console.Write(
                $&quot;Could not load your {(imageCount == 1 ? &quot;image&quot; : &quot;images&quot;)}:&quot;);
            Console.Write($&quot;{exception.Message}&quot;);
            Console.ForegroundColor = ConsoleColor.Yellow;
            Console.WriteLine(&quot;Please try again.&quot;);
            break;
        }


        int index = 0;
        foreach (var path in imagePathsWithCurlyBraces)
        {
            // First image replace to tag &lt;image, the rest of the images delete the tag
            if (index++ == 0)
                prompt = prompt.Replace(path, &quot;&lt;image&gt;&quot;);
            else
                prompt = prompt.Replace(path, &quot;&quot;);
        }
        Console.WriteLine();


        // Initilize Images in executor
        //
        ex.ImagePaths = imagePaths.ToList();
    }

    Console.ForegroundColor = ConsoleColor.White;
    await foreach (var text in ex.InferAsync(prompt, inferenceParams))
    {
        Console.Write(text);
    }
    Console.Write(&quot; &quot;);
    Console.ForegroundColor = ConsoleColor.Green;
    prompt = Console.ReadLine();
    Console.WriteLine();

    // let the user finish with exit
    //
    if (prompt.Equals(&quot;/exit&quot;, StringComparison.OrdinalIgnoreCase))
        break;

}
while (true);
</code></pre>
<p><em>For more examples, please refer to <a href="./LLama.Examples">LLamaSharp.Examples</a>.</em></p>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.74e28a9f.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"provider": "mike"}}</script>
    
    
      <script src="../assets/javascripts/bundle.220ee61c.min.js"></script>
      
    
  </body>
</html>